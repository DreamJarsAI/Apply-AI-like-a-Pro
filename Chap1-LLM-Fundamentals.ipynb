{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63f0174",
   "metadata": {},
   "source": [
    "# Book: Learning LangChain \n",
    "by Mayo Oshin and Nuno Campos\n",
    "\n",
    "## Chapter 1. LLM Fundamentals with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d10a87a-2cc4-4bbb-bccd-a2ea0649971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "%pip install langchain langchain_openai langchain_community langchain-text-splitters  -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eace992-4628-49ed-8d80-e7c3c7f3e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.runnables import chain\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bece3a5-c418-4d62-b4fb-03b0c2ef9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "load_dotenv()\n",
    "OpenAI.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36387706",
   "metadata": {},
   "source": [
    "# Use the LLMs with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d256602a-6751-49c8-815b-c24dd7caeddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The meaning of life is a philosophical and existential question that has been pondered by humans for centuries. It refers to the purpose, significance, or ultimate goal of human existence. Different individuals and cultures may have different beliefs and perspectives on the meaning of life, but some common themes include finding happiness, fulfilling one's potential, making a positive impact, and seeking spiritual fulfillment. Ultimately, the meaning of life is a subjective concept and can be interpreted differently by each individual.\n"
     ]
    }
   ],
   "source": [
    "# Call an OpenAI LLM model (rather than a ChatModel)\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "# Invoke the model\n",
    "prompt = \"What is the meaning of life?\"\n",
    "response = llm.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89cd2a8",
   "metadata": {},
   "source": [
    "# Use the ChatModel with LangChain\n",
    "\n",
    "HumanMessage\n",
    "A message sent from the perspective of the human, with the user role.\n",
    "\n",
    "AIMessage\n",
    "A message sent from the perspective of the AI the human is interacting with, with the assistant role.\n",
    "\n",
    "SystemMessage\n",
    "A message setting the instructions the AI should follow, with the system role.\n",
    "\n",
    "ChatMessage\n",
    "A message allowing for arbitrary setting of role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11e03af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of Japan is Tokyo.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-767eb490-966f-486e-8838-c973e280b063-0' usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "\n",
      "\n",
      "The capital of Japan is Tokyo.\n"
     ]
    }
   ],
   "source": [
    "# Innitialize the chat model\n",
    "chatmodel = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create a human message\n",
    "prompt = [HumanMessage('What is the capital of Japan?')]\n",
    "\n",
    "# Invoke the chat model\n",
    "completion = chatmodel.invoke(prompt)\n",
    "print(completion)\n",
    "print(\"\\n\")\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1954b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris!!!\n"
     ]
    }
   ],
   "source": [
    "# Add a system message\n",
    "system_msg = SystemMessage('You are a helpful assistant that responds to questions with three exclamation marks.')\n",
    "human_msg = HumanMessage('What is the capital of France?')\n",
    "completion = chatmodel.invoke([system_msg, human_msg])\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0eecd",
   "metadata": {},
   "source": [
    "# Make LLM prompts reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1cd8412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don\\'t know\".\\nContext: \\nA utopia typically describes an imaginary community or society that possesses highly desirable or near-perfect qualities for its members.[1] It was coined by Sir Thomas More for his 1516 book Utopia, which describes a fictional island society in the New World.\\nHypothetical utopias focus on, among other things, equality in categories such as economics, government and justice, with the method and structure of proposed implementation varying according to ideology.[2] Lyman Tower Sargent argues that the nature of a utopia is inherently contradictory because societies are not homogeneous and have desires which conflict and therefore cannot simultaneously be satisfied.\\n\\nQuestion: When was Abraham Lincoln born?\\nAnswer: \\n'\n",
      "\n",
      "\n",
      "Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
      "Context: \n",
      "A utopia typically describes an imaginary community or society that possesses highly desirable or near-perfect qualities for its members.[1] It was coined by Sir Thomas More for his 1516 book Utopia, which describes a fictional island society in the New World.\n",
      "Hypothetical utopias focus on, among other things, equality in categories such as economics, government and justice, with the method and structure of proposed implementation varying according to ideology.[2] Lyman Tower Sargent argues that the nature of a utopia is inherently contradictory because societies are not homogeneous and have desires which conflict and therefore cannot simultaneously be satisfied.\n",
      "\n",
      "Question: When was Abraham Lincoln born?\n",
      "Answer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template\n",
    "template = PromptTemplate.from_template(\n",
    "\"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: \n",
    "\"\"\")\n",
    "\n",
    "# Invoke the prompt template\n",
    "context = \"\"\"\n",
    "A utopia typically describes an imaginary community or society that possesses highly desirable or near-perfect qualities for its members.[1] It was coined by Sir Thomas More for his 1516 book Utopia, which describes a fictional island society in the New World.\n",
    "Hypothetical utopias focus on, among other things, equality in categories such as economics, government and justice, with the method and structure of proposed implementation varying according to ideology.[2] Lyman Tower Sargent argues that the nature of a utopia is inherently contradictory because societies are not homogeneous and have desires which conflict and therefore cannot simultaneously be satisfied.\n",
    "\"\"\"\n",
    "question = \"When was Abraham Lincoln born?\"\n",
    "prompt = template.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": question\n",
    "})\n",
    "print(prompt)\n",
    "print(\"\\n\")\n",
    "print(prompt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd4c018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Feed the prompt to the LLM\n",
    "completion = llm.invoke(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2ba70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Build a chat prompt template\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don\\'t know\".'),\n",
    "    ('human', 'Context: {context}'),\n",
    "    ('human', 'Question: {question}'),\n",
    "])\n",
    "prompt = template.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": question\n",
    "})\n",
    "\n",
    "# Create a chat completion\n",
    "completion = chatmodel.invoke(prompt)\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d3bfb",
   "metadata": {},
   "source": [
    "# Produce JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19a1cc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='No, people cannot go back in time and change history.' justification='According to current scientific understanding, time travel to the past is not possible. The laws of physics, such as causality and the conservation of energy, make it unlikely that time travel to the past could ever be achieved.'\n",
      "\n",
      "\n",
      "No, people cannot go back in time and change history.\n",
      "\n",
      "\n",
      "According to current scientific understanding, time travel to the past is not possible. The laws of physics, such as causality and the conservation of energy, make it unlikely that time travel to the past could ever be achieved.\n"
     ]
    }
   ],
   "source": [
    "# Create a template using the pydantic basemodel\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user question along with justification for the answer.'''\n",
    "    answer: str\n",
    "    '''The answer to the user's question'''\n",
    "    justification: str\n",
    "    '''Justification for the answer'''\n",
    "\n",
    "# Create a prompt\n",
    "prompt = \"Could people go back in time and change history?\"\n",
    "\n",
    "# Create structured output\n",
    "# Note: with_structured_output will apply the JSONSchema to the chatmodel output\n",
    "structured_chatmodel = chatmodel.with_structured_output(AnswerWithJustification)\n",
    "structured_output = structured_chatmodel.invoke(prompt)\n",
    "print(structured_output)\n",
    "print(\"\\n\")\n",
    "print(structured_output.answer)\n",
    "print(\"\\n\")\n",
    "print(structured_output.justification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49919b",
   "metadata": {},
   "source": [
    "# Other machine-readable formats with output parsers (CSV, XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02ec2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'two', 'three', 'four', 'five']\n"
     ]
    }
   ],
   "source": [
    "# Use the CommaSeparatedListOutputParser to parse a comma-separated list of items\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "items = parser.invoke(\"one, two, three, four, five\")\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf661ef",
   "metadata": {},
   "source": [
    "# Using the runnable interface\n",
    "\n",
    "A common interface with these methods:\n",
    "\n",
    "invoke\n",
    "Transforms a single input into an output.\n",
    "\n",
    "batch\n",
    "Efficiently transforms multiple inputs into multiple outputs.\n",
    "\n",
    "stream\n",
    "Streams output from a single input as it’s produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2afba9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning! How may I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# The invoke interface\n",
    "completion = chatmodel.invoke('Good morning!')\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88bd548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a computer program, so I don't have feelings or emotions, but I'm here to help you with anything you need. How can I assist you today?\n",
      "\n",
      "\n",
      "Not much, just here to assist you with anything you need. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# The batch interface\n",
    "completions = chatmodel.batch([\"How are you?\", \"What is up, bro?\"])\n",
    "print(completions[0].content)\n",
    "print(\"\\n\")\n",
    "print(completions[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71496e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good\n",
      "bye\n",
      "!\n",
      " Take\n",
      " care\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The stream interface\n",
    "for token in chatmodel.stream('See you!'):\n",
    "    print(token.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f1bef",
   "metadata": {},
   "source": [
    "# Combine the different LLM components\n",
    "\n",
    "Imperative\n",
    "Call them directly, for example with model.invoke()\n",
    "\n",
    "Declarative\n",
    "With LangChain Expression Language (LCEL) using pipe (i.e., |)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f3058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key difference between stemming and lemmatization lies in their approach to reducing words to their base or root form. \n",
      "\n",
      "Stemming involves cutting off prefixes or suffixes from words to get to the base form, which may not always result in a proper word. For example, the word \"running\" would be stemmed to \"run\", but \"run\" is a valid word on its own.\n",
      "\n",
      "On the other hand, lemmatization involves looking up words in a language dictionary to find the base or root form, known as the lemma. This results in a valid word that makes sense in the language. Using the same example, \"running\" would be lemmatized to \"run\", which is a proper dictionary word.\n",
      "\n",
      "In summary, stemming is a more basic and heuristic process, while lemmatization is a more sophisticated and accurate method of reducing words to their base form.\n"
     ]
    }
   ],
   "source": [
    "# The imperative apporach\n",
    "\n",
    "# Build a chat prompt template\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}'),\n",
    "])\n",
    "\n",
    "# Call a chatmodel\n",
    "chatmodel = ChatOpenAI()\n",
    "\n",
    "# Combine the prompt template and the chatmodel in a function\n",
    "# Note: @chain decorator adds the same Runnable interface for any function you write\n",
    "@chain\n",
    "def chatbot(question):\n",
    "    prompt = template.invoke(question)\n",
    "    return chatmodel.invoke(prompt)\n",
    "\n",
    "# Invote the above function with a question\n",
    "question = \"What is the key difference between stemming and lemmatization?\"\n",
    "result = chatbot.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd3de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The\n",
      " planet\n",
      " closest\n",
      " to\n",
      " Earth\n",
      " is\n",
      " Venus\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a streaming chatbot using the imperative appraoch\n",
    "@chain\n",
    "def chatbot(question):\n",
    "    prompt = template.invoke(question)\n",
    "    for token in chatmodel.stream(prompt):\n",
    "        yield token.content\n",
    "\n",
    "# Run the chatbot\n",
    "question = \"Whis planet is closest to the Earth?\"\n",
    "for part in chatbot.stream(question):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd8b2764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To put an elephant into a fridge, you would need to follow these steps:\n",
      "\n",
      "1. Open the fridge door.\n",
      "2. Move any items that are currently inside the fridge to make space for the elephant.\n",
      "3. Guide or lead the elephant towards the open fridge door.\n",
      "4. Gently encourage or assist the elephant in entering the fridge.\n",
      "5. Once the elephant is inside the fridge, carefully close the door.\n",
      "\n",
      "It's important to note that this is a hypothetical scenario and not something that should actually be attempted with a real elephant, as it is neither safe nor ethical to put an elephant into a fridge.\n"
     ]
    }
   ],
   "source": [
    "# Asynchronous function\n",
    "@chain\n",
    "async def chatbot(question):\n",
    "    prompt = await template.ainvoke(question)\n",
    "    return await chatmodel.ainvoke(prompt)\n",
    "\n",
    "# Invoke the chatbot asynchronously\n",
    "result = await chatbot.ainvoke({\n",
    "    \"question\": \"How to put an elephant into a fridge?\"\n",
    "})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e254d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update, the current president of the United States is Joe Biden.\n"
     ]
    }
   ],
   "source": [
    "# Declarative approach using pipe, i.e., |\n",
    "chatbot = template | chatmodel\n",
    "result = chatbot.invoke({\n",
    "    \"question\": \"Who is the current president of the United States?\"\n",
    "})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86fa24cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good\n",
      " evening\n",
      "!\n",
      " How\n",
      " can\n",
      " I\n",
      " assist\n",
      " you\n",
      " today\n",
      "?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declarative approach with stream\n",
    "chatbot = template | chatmodel\n",
    "for part in chatbot.stream({\n",
    "    \"question\": \"Good evening!\"\n",
    "}):\n",
    "    print(part.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62933104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Australia is Canberra.\n"
     ]
    }
   ],
   "source": [
    "# Declarative approach with asynchonous execution\n",
    "chatbot = template | chatmodel\n",
    "result = await chatbot.ainvoke({\n",
    "    \"question\": \"What is the capital of Australia?\",\n",
    "})\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
